# Run Deepseek R1 Locally

Here's some ways to quickly get started running [Deepseek R1](https://www.deepseek.com/) locally on your machine. I ran these using an M1 Macbook Pro, using the 4.7GB [deepseek-r1:7b](https://ollama.com/library/deepseek-r1:7b) model

## Run Deepseek with LM Studio (UI)

LM Studio is a free app that lets you run language models on your own machine. 

* Download it from https://lmstudio.ai.
* Download the Deepseek R1 (Qwen) model through LM Studio's interface and start chatting. The interface displays token usage and shows the model's thought process as it generates responses.

I used the 7B parameter model, which is OK for testing functionality, but not really that powerful.
